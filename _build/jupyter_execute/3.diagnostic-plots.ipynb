{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6b3fd6-1753-45e7-a920-fccf68cbdcac",
   "metadata": {},
   "source": [
    "# Diagnostic Plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e89221",
   "metadata": {},
   "source": [
    "## Standard Diagnostic Plots\n",
    "\n",
    "### Residual vs Fitted Plot\n",
    "\n",
    "### Q-Q Normal Plot\n",
    "\n",
    "### Scale vs Location Plot\n",
    "\n",
    "### Residuals vs Leverage Plot\n",
    "Cook's distance..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2271863",
   "metadata": {},
   "source": [
    "`````{admonition} Residuals are Not Independent with Constant Variance\n",
    ":class: tip\n",
    "One of the main reasons for distinguishing between *errors* and *residuals* is that the estimation process *changes* the distributional properties of the errors. This means that *errors* and *residuals* are not expected to behave idnetically. So while it is correct to assume\n",
    "\n",
    "$$\n",
    "\\epsilon_{i} \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{N}\\left(0,\\sigma^{2}\\right),\n",
    "$$\n",
    "\n",
    "it is *not* technically correct to assume the same for the *errors*. This is because the estimation procedure can *induce* correlation between the errors and the errors can have non-constant variance, depending upon a property known as *leverage*. We will discuss some of these concepts next week. For now, just note that the residuals can be used as an *approximation* for the errors, but we need to perform some additional checks to make sure that this approximation is reasonable.\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf96efc",
   "metadata": {},
   "source": [
    "[^VIF-foot]: Note that some authors suggest VIF > 10 to be the marker for concerning multicollinearity. Here, we would recommend the more cautious approach of using VIF > 5.\n",
    "\n",
    "[^NASA-foot]: [Faraway (2005)](https://www.utstat.toronto.edu/~brunner/books/LinearModelsWithR.pdf) provides a real-world example of why this is *not* good practise. This concerns the delay in the discovery of the hole in the Ozone layer due to NASA's automatic data analysis algorithms discarding very low readings assumed to be mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f56329c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}