
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>The Linear Model Assumptions &#8212; Linear Models III: Assumptions, Diagnostics and Transformations</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/test.css?v=90b7ad94" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '1.assumptions';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Data Features" href="2.data-features.html" />
    <link rel="prev" title="Introduction" href="0.intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="0.intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Linear Models III: Assumptions, Diagnostics and Transformations - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="Linear Models III: Assumptions, Diagnostics and Transformations - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0.intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">The Linear Model Assumptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="2.data-features.html">Data Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.diagnostic-measures.html">Diagnostic Measures</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.diagnostic-plots.html">Diagnostic Plots</a></li>
<li class="toctree-l1"><a class="reference internal" href="5.transformations.html">Transformations</a></li>
<li class="toctree-l1"><a class="reference internal" href="6.adjusting-model.html">Adjusting the Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="summary.html">Summary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/PCHN63101-Advanced-Data-Skills/Assumptions-Diagnostics-Transforms" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/PCHN63101-Advanced-Data-Skills/Assumptions-Diagnostics-Transforms/issues/new?title=Issue%20on%20page%20%2F1.assumptions.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/1.assumptions.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>The Linear Model Assumptions</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-nature-of-assumptions-visual-checks-and-tests">The Nature of Assumptions, Visual Checks and Tests</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-visual-assessments">Using Visual Assessments</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-tests-of-assumptions-are-flawed">Why Tests of Assumptions are Flawed</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-regression-assumptions">The Regression Assumptions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-outcome-is-a-continuous-random-variable">(1) The Outcome is a Continuous Random Variable</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-distribution-of-the-errors-is-normal">(2) The Distribution of the Errors is Normal</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-data-errors-are-uncorrelated">(3) The Data/Errors are Uncorrelated</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-relationship-is-a-straight-line">(4) The Relationship is a Straight Line</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-variance-is-constant">(5) The Variance is Constant</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="the-linear-model-assumptions">
<h1>The Linear Model Assumptions<a class="headerlink" href="#the-linear-model-assumptions" title="Link to this heading">#</a></h1>
<p>In the previous weeks, we outlined the modelling framework behind both simple and multiple regression. In doing so, we made a number of assumptions that allowed this framework to be tractable and useable. However, we never acually checked whether any of these assumptions held when using our example data. In this section, we will discuss the nature of checking modelling assumptions, as well as discussing each of the assumptions we made. In the rest of this lesson, we will discuss standard ways of checking these assumptions, as well as tactics that can be employed when those assumptions appear to be violated.</p>
<div class="tip admonition">
<p class="admonition-title">The Generality of Assumptions</p>
<p>One of the bigger benefits of using a linear models framework is that, irrespective of the model form, the assumptions remain the same. As such, even though we will be framing these assumptions in relation to muliple regression, all the methods we will discuss are also directly relevant to <span class="math notranslate nohighlight">\(t\)</span>-tests, ANOVA and ANCOVA models. This means we can use the same diagnostics to check the same assumptions across any model. Practically, this means we only need to learn <em>one</em> set of assumptions and then can apply them to any model we choose. This is much more efficient than the typical approach of listing assumptions separately for regression, ANOVA and ANCOVA models. Furthermore, the solutions used to accommodate violations of these assumptions can be applied across regression, ANOVA and ANCOVA models, meaning that this lesson should be seen as a flexible set of tools that can be used for <em>all</em> linear models, not just for multiple regression.</p>
</div>
<section id="the-nature-of-assumptions-visual-checks-and-tests">
<h2>The Nature of Assumptions, Visual Checks and Tests<a class="headerlink" href="#the-nature-of-assumptions-visual-checks-and-tests" title="Link to this heading">#</a></h2>
<p>Before discussion the assumptions themseleves, it is important that we establish a suitable perspective on assumptions and assumption testing. Typically, in the behavioural sciences, assumptions are not adequately checked. In part, this reflects a lack of appreciation for the importance of assumptions and, in part, reflects a lack of confidence around what to do if the assumptions are violated. When assumptions <em>are</em> tested, this is typically via <em>inferential tests</em>. In this course, we are going to advise against relying on tests for assessing assumptions. Instead, our focus will be on visual inspection of the assumptions.</p>
<p>One of the key reasons why we caution against inferential tests is because they rely on NHST, with all the problems we discussed last week. In this context, it is especially important that assumptions are not considered black-and-white assessments of <em>met</em> or <em>violated</em>. In reality, no data will ever be perfectly normally distributed. No data will have identical variances across its range. No relationship will be a perfect straight line. Assumptions are an idealisation of reality in the name of mathematical simplicity. Our job is to determine whether the data are <em>close enough</em> for our conclusions to be accurate. If they are not close enough, then we need to either try and make adjustments, or we have to accept the consequences of these violations. Real world data is messy and so it is important to maintain both an appropriate perspective on the role of assumptions, as well as having enough tools available to deal with data that does not adequately adhere to those assumptions.</p>
<section id="using-visual-assessments">
<h3>Using Visual Assessments<a class="headerlink" href="#using-visual-assessments" title="Link to this heading">#</a></h3>
<p>Visual assessments of the model assumptions involve plotting aspects of the model in such a way that any violations of assumptions have a clear visual signature. All these types of plots are designed with this purpose in mind. Indeed, this is the way that working statisticians recommend the assumptions are checked. We can see this in <code class="docutils literal notranslate"><span class="pre">R</span></code>, where we ask for plots from a model fit with <code class="docutils literal notranslate"><span class="pre">lm()</span></code> and the following are produced</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">data</span><span class="p">(</span><span class="n">mtcars</span><span class="p">)</span>
<span class="n">mod</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lm</span><span class="p">(</span><span class="n">mpg</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">wt</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">hp</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cyl</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">mtcars</span><span class="p">)</span>

<span class="nf">par</span><span class="p">(</span><span class="n">cex</span><span class="o">=</span><span class="m">1.6</span><span class="p">)</span><span class="w"> </span><span class="c1"># plot scaling</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/9238ec1c619d6741bea56cfb533651774b180cbf7a75aedb802dc187cad71d8d.png"><img alt="_images/9238ec1c619d6741bea56cfb533651774b180cbf7a75aedb802dc187cad71d8d.png" src="_images/9238ec1c619d6741bea56cfb533651774b180cbf7a75aedb802dc187cad71d8d.png" style="width: 720px; height: 420px;" /></a>
<a class="reference internal image-reference" href="_images/60194fff94846f186621289247922d7cf8eb8188e07167058ac7b664a15b38af.png"><img alt="_images/60194fff94846f186621289247922d7cf8eb8188e07167058ac7b664a15b38af.png" src="_images/60194fff94846f186621289247922d7cf8eb8188e07167058ac7b664a15b38af.png" style="width: 720px; height: 420px;" /></a>
<a class="reference internal image-reference" href="_images/780faa42c2fc419e65699c952dfbeaa7b1f2cd56615ded9d5315a412dd0abe46.png"><img alt="_images/780faa42c2fc419e65699c952dfbeaa7b1f2cd56615ded9d5315a412dd0abe46.png" src="_images/780faa42c2fc419e65699c952dfbeaa7b1f2cd56615ded9d5315a412dd0abe46.png" style="width: 720px; height: 420px;" /></a>
<a class="reference internal image-reference" href="_images/a31141353024712b9c46058dbbe76237fc76036e6af3af5df790d5c384b9f28c.png"><img alt="_images/a31141353024712b9c46058dbbe76237fc76036e6af3af5df790d5c384b9f28c.png" src="_images/a31141353024712b9c46058dbbe76237fc76036e6af3af5df790d5c384b9f28c.png" style="width: 720px; height: 420px;" /></a>
</div>
</div>
<p>We will discuss what all these plots are showing us and how to interpret them later in this lesson. For now, just notice that the default method in <code class="docutils literal notranslate"><span class="pre">R</span></code> is to draw plots to check assumptions, <em>not</em> run a bunch of inferential tests of assumptions. This is for very good reason, as we will now discuss.</p>
</section>
<section id="why-tests-of-assumptions-are-flawed">
<h3>Why Tests of Assumptions are Flawed<a class="headerlink" href="#why-tests-of-assumptions-are-flawed" title="Link to this heading">#</a></h3>
<p>One of the reasons why researchers are sometimes uncomfortable with visual assessments is because they think that the interpetion is too subjective. Of course, there is a subjective element to deciding whether the assumptions appear adequately met, however, the belief that there is some objective alternative to determine this is flawed. Because inferential tests of these assumptions exist, there is a belief that these methods therefore provide a way of determining whether the assumptions are violated that is free from researcher bias. However, these tests are flawed. In the previous lesson, we discussed the problems with <span class="math notranslate nohighlight">\(p\)</span>-values and these issues carry-over into the world of inferential tests of model assumptions. If we do not believe that data will ever be <em>perfectly</em> normally distribution, or have <em>exactly the same</em> variance across the range of a variable, then the null hypothesis is known <em>a priori</em> to not be true. In this situation, all we need is enough data in order to conclude a significant violation of the assumption. Furthermore, tests of assumptions require assumptions themseleves in order to calculate <span class="math notranslate nohighlight">\(p\)</span>-values. Although rarely checked, the use of inferential tests for this purpose is then somewhat circular. Do we need inferential tests to check the assumptions of the inferential tests of assumptions?</p>
<p>We can demonstrate some of these issue using simulated data. Here, we will use the Shapiro-Wilk test of normality to illustrate some problems. Firstly, we will generate a <em>small</em> sample of data from a <span class="math notranslate nohighlight">\(t\)</span>-distribution. Importantly, this is <em>not</em> a normal distribution and so if the test is objective and correct it should tell us that there is a significant depature from normality. Let us see what happens.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">666</span><span class="p">)</span>
<span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">15</span>
<span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">rt</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="o">=</span><span class="m">3</span><span class="p">)</span>

<span class="c1"># Run Shapiro-Wilk test</span>
<span class="n">shap.test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">shapiro.test</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">shap.test</span><span class="p">)</span>

<span class="c1"># Visualisation</span>
<span class="nf">par</span><span class="p">(</span><span class="n">cex.lab</span><span class="o">=</span><span class="m">1.3</span><span class="p">,</span><span class="w"> </span><span class="n">cex.axis</span><span class="o">=</span><span class="m">1.1</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="o">=</span><span class="m">1.4</span><span class="p">)</span><span class="w"> </span><span class="c1"># plot scaling</span>
<span class="nf">hist</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">probability</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s">&quot;Small Sample Histogram&quot;</span><span class="p">,</span><span class="w"> </span>
<span class="w">     </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;skyblue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="n">.</span><span class="m">6</span><span class="p">),</span><span class="w"> </span><span class="n">xlim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">-4</span><span class="p">,</span><span class="m">4</span><span class="p">),</span><span class="w"> </span><span class="n">breaks</span><span class="o">=</span><span class="m">15</span><span class="p">)</span>
<span class="nf">curve</span><span class="p">(</span><span class="nf">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">add</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>	Shapiro-Wilk normality test

data:  y
W = 0.95294, p-value = 0.5719
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/e710589e3cb2e65f0bb7976d3c7aba4f2890c5f4cf7281bd2fb3357f5a321069.png"><img alt="_images/e710589e3cb2e65f0bb7976d3c7aba4f2890c5f4cf7281bd2fb3357f5a321069.png" src="_images/e710589e3cb2e65f0bb7976d3c7aba4f2890c5f4cf7281bd2fb3357f5a321069.png" style="width: 720px; height: 420px;" /></a>
</div>
</div>
<p>The test has produced a <em>non-significant</em> <span class="math notranslate nohighlight">\(p\)</span>-value, which tells us that the test has failed to reject the null hypothesis that our data comes from a normal distribution. This would usually be interpreted as <em>no significant depature from normality</em>. The important point is that we know this is wrong. Would we have noticed this lack of normality from the visualisation? Looking the plot, we can see that the small sample actually makes it quite difficult to determine the distribution. Based on this, we should at least be wary of accepting any particular shape, but this is a subtlety that <em>cannot</em> be conveyed with the test. Importantly, the inferential test has not provided us with a correct objective alternative to our “subjective” interpretation of the plot.</p>
<p>Let us see another example. This time we generate a <em>large</em> sample with a trivial depature from normality. The way we do this is by mixing together two normal distributions such that the overall distribution is only slightly non-normal. The aim is to do this in such a subtle way that it would have no practical implications. This is a situation where the data are <em>close enough</em> to the ideal for us to be confident that our model calculations will be accurate. But let us see what the test says.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">set.seed</span><span class="p">(</span><span class="m">123</span><span class="p">)</span>
<span class="n">n</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">2000</span>
<span class="n">y</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="m">0.9</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="m">1</span><span class="p">),</span>
<span class="w">       </span><span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="m">0.1</span><span class="p">,</span><span class="w"> </span><span class="n">mean</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">sd</span><span class="o">=</span><span class="m">1</span><span class="p">))</span>

<span class="c1"># Run Shapiro-Wilk tests</span>
<span class="n">shap.test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">shapiro.test</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">shap.test</span><span class="p">)</span>

<span class="c1"># Visualisation</span>
<span class="nf">par</span><span class="p">(</span><span class="n">cex.lab</span><span class="o">=</span><span class="m">1.3</span><span class="p">,</span><span class="w"> </span><span class="n">cex.axis</span><span class="o">=</span><span class="m">1.1</span><span class="p">,</span><span class="w"> </span><span class="n">cex</span><span class="o">=</span><span class="m">1.4</span><span class="p">)</span><span class="w"> </span><span class="c1"># plot scaling</span>
<span class="nf">hist</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">probability</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s">&quot;Large Sample Histogram&quot;</span><span class="p">,</span><span class="w"> </span>
<span class="w">     </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;skyblue&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span><span class="n">.</span><span class="m">45</span><span class="p">),</span><span class="w"> </span><span class="n">xlim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">-4</span><span class="p">,</span><span class="m">4</span><span class="p">),</span><span class="w"> </span><span class="n">breaks</span><span class="o">=</span><span class="m">25</span><span class="p">)</span>
<span class="nf">curve</span><span class="p">(</span><span class="nf">dnorm</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="w"> </span><span class="n">col</span><span class="o">=</span><span class="s">&quot;red&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lwd</span><span class="o">=</span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="n">add</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>	Shapiro-Wilk normality test

data:  y
W = 0.99836, p-value = 0.04526
</pre></div>
</div>
<a class="reference internal image-reference" href="_images/621ce193084ad0171785ac94534de039dfd7c0837f3c927ce09744ec507ff0cf.png"><img alt="_images/621ce193084ad0171785ac94534de039dfd7c0837f3c927ce09744ec507ff0cf.png" src="_images/621ce193084ad0171785ac94534de039dfd7c0837f3c927ce09744ec507ff0cf.png" style="width: 720px; height: 420px;" /></a>
</div>
</div>
<p>Here, the test says that there is a <em>significant</em> violation of normality. The test is not wrong, however, looking at the histogram it is very clear that the violation of slightly more density on the positive side of the distribution is very trivial. Practically, the distribution looks as close to normal as we are ever likely to see with real data. Based on this histogram, any attempt to correct for non-normality would likely be taken as wildly unnecessary. However, if we just believed the test then we could be off on a wild goose chase trying to change our model and transform our data to accomodate this violation. Again, visualising this assumption gives us the richest information for deciding how close to normal the distribution is and how comfortable we are relying on results that depend upon this assumption.</p>
<div class="tip admonition">
<p class="admonition-title">Being <em>Open</em> About Assumption Visualisations</p>
<p>One of the most obvious worries about visual assumptions is that researchers who are desperate to generate results from their data could easily just dismiss very clear violations in these plots. This would be as simple as writing “visualisations of the assumptions revealed no concerning violations” in their paper. However, what we need to do as a field is <em>force</em> the addition of these assumption visualisations as supplementary materials for all papers. You cannot hide them if you are forced to publish them. So whenever evaluating these plots, try and think about whether they would convince other people? Think about whether you would be comfortable publishing these plots as part of a scientific publication? Lead the way by including them as supplementary materials and, as a reviewer, insist that authors make these plots public.</p>
</div>
</section>
</section>
<section id="the-regression-assumptions">
<h2>The Regression Assumptions<a class="headerlink" href="#the-regression-assumptions" title="Link to this heading">#</a></h2>
<p>Now that we have an appropriate perspective on testing these assumptions, let us now detail the assumptions that are inherent in the linear model we have been using over the last few weeks. This is quite an important exericse, because the assumptions of regression often seem somewhat esoteric when taught outside the framework of statistical models. However, we should be able to derive all of them by simply examining the model equations we have used. This is the same approach we will take when we examine models such as ANOVA and ANCOVA, which will allow us to see that the assumptions <em>are always the same</em> when working within the linear models framework. To facilitate this discussion, let us restate the simple regression model</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
    y_{i}        &amp;= \beta_{0} + \beta_{1}x_{i} + \epsilon_{i} \\
    \epsilon_{i} &amp;\overset{\text{i.i.d.}}{\sim} \mathcal{N}\left(0,\sigma^{2}\right).
\end{align*}
\end{split}\]</div>
<p>We have cheated a little here and added the text <span class="math notranslate nohighlight">\(i.i.d.\)</span> into the definition of the errors. We will discuss what this means below. However, with this addition, all the assumptions we have made in this model are written in the two lines above. Let us now unpack this in more detail.</p>
<section id="the-outcome-is-a-continuous-random-variable">
<h3>(1) The Outcome is a Continuous Random Variable<a class="headerlink" href="#the-outcome-is-a-continuous-random-variable" title="Link to this heading">#</a></h3>
<p>The first assumption we have made is that the outcome variable is a continuous random variable. As such, the <em>data-generating process</em> can be captured by some continuous probability distribution. This means our outcome variables must, in theory, have an infinite number of possibilities within a given range. You can refer back to the lessons earlier in the course for more details on this, as well as some of the subtlties around psychologists using discrete measures and treating them as continuous. Just know that if the outcome variable is <em>not</em> truly continuous then there may be some unexpected behaviour when checking other assumptions. This is because the data will not necessarily be spread across a wide range and will, instead, cluster at discrete points.</p>
</section>
<section id="the-distribution-of-the-errors-is-normal">
<h3>(2) The Distribution of the Errors is Normal<a class="headerlink" href="#the-distribution-of-the-errors-is-normal" title="Link to this heading">#</a></h3>
<p>Following from the first assumption, we have chosen the normal distribution as the continuous probability distribution used to represent our population of interest. This assumption can be stated in two ways. The first is as a <em>marginal</em> distribution of <span class="math notranslate nohighlight">\(y\)</span>, given a specific value of <span class="math notranslate nohighlight">\(x\)</span>. This is expressed as</p>
<div class="math notranslate nohighlight">
\[
y_{i} \sim \mathcal{N}\left(\beta_{0} + \beta_{1}x_{i},\sigma^{2}\right).
\]</div>
<p>This particular form is important to understand, not least because many people <em>get it wrong</em>. As should be clear from the equation above, the simple regression model does <em>not</em> assume that the entire outcome variable <span class="math notranslate nohighlight">\(y\)</span> is normally distributed. Instead, the assumption is that the distribution of <span class="math notranslate nohighlight">\(y\)</span> <em>at each value of <span class="math notranslate nohighlight">\(x\)</span></em> is normally distributed. Considering only the distribution of a <em>subset</em> of <span class="math notranslate nohighlight">\(y\)</span> values is known as the <em>marginal</em> distribution of <span class="math notranslate nohighlight">\(y\)</span> given certain values of <span class="math notranslate nohighlight">\(x\)</span>. However, as we will see later in this lesson, this form is difficult to work with practically. This is because we would need enough values of <span class="math notranslate nohighlight">\(y\)</span> at each value of <span class="math notranslate nohighlight">\(x\)</span> to be able to assess the shape of the distribution. Furthermore, when <span class="math notranslate nohighlight">\(x\)</span> has a wide range, we cannot do this in any practical way. As such, it is much easier to work with the <em>second form</em> that this assumption takes, which is that the <em>errors</em> are normally distributed with mean 0. This is expressed as</p>
<div class="math notranslate nohighlight">
\[
\epsilon_{i} \sim \mathcal{N}\left(0,\sigma^{2}\right).
\]</div>
<p>Every error is therefore drawn from <em>the same distribution</em>. In other words, the errors represents a <em>sample</em> from a single distribution. Because of this, we can collapse all the errors together and just examine <em>one distribution</em>. Again, refer back to the content from earlier if you need a reminder of why this assumption can be stated in two different ways.</p>
</section>
<section id="the-data-errors-are-uncorrelated">
<h3>(3) The Data/Errors are Uncorrelated<a class="headerlink" href="#the-data-errors-are-uncorrelated" title="Link to this heading">#</a></h3>
<p>Another important assumption is that the data/errors are <em>uncorrelated</em>. When writing the simple regression model above, we added the text <span class="math notranslate nohighlight">\(i.i.d.\)</span> to the definition of the errors. This means <em>independent and identically distributed</em>. The <em>identically distributed</em> part should be clear from the previous assumption, where each error is conceptually drawn from the <em>same</em> distribution. However, the <em>independent</em> part is also very important, but has been somewhat hidden until this point. In short, the model assumes that there is <em>no correlation</em> between the datapoints. This is implicit in the fact that no correlation is estimated, nor is it taken into account during any of the model calculations. As such, the implicit assumption is that</p>
<div class="math notranslate nohighlight">
\[
\text{Corr}\left(y_{i},y_{i^{\prime}}\right) = \text{Corr}\left(\epsilon_{i},\epsilon_{i^{\prime}}\right) = 0,
\]</div>
<p>where the prime symbol is used to indicate that <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(i^{\prime}\)</span> should be taken as <em>different</em> numbers<a class="footnote-reference brackets" href="#prime-foot" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>. As such, we are assuming that the data (and by extension the errors) are <em>independent</em> of each other.</p>
<p>Typically, this is not actually an assumption we test, rather we infer it based on the context of the data collection. For instance, in the <code class="docutils literal notranslate"><span class="pre">mtcars</span></code> example, there is no reason to think that the measurement of <code class="docutils literal notranslate"><span class="pre">mpg</span></code> from one car would impact the measurement from any other car. We therefore assume that all cars are independent and there will be no correlation. However, if we made the same measurement multiple times <em>on the same car</em>, then we would probably assume some degree of correlation (this would be an example of <em>repeated measurements</em>). The same is true of working with human subjects. When each measurement represents a different subject, we will typically assume independence. However, multiple measures of the same subject imply some degree of correlation and will require a different approach to modelling the data. We will see this later on the course in the form of <em>mixed-effects models</em>. But, for the time being, we will only be working with data assumed to be <em>independent</em><a class="footnote-reference brackets" href="#repmeasures-foot" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>.</p>
<div class="tip admonition">
<p class="admonition-title">Why Does Correlation Matter?</p>
<p>It may not be entirely clear at this stage why correlation would be such a concern. Although we will cover this in more detail later in the course, the short answers is that correlation adds quite a lot of complexity to modelling the data. This is both in terms of estimation, but also in terms of the correct calculation of standard errors when data are non-independent. For instance, a standard result in probability is that the variance of the <em>difference</em> between two random variables is</p>
<div class="math notranslate nohighlight">
\[
\text{Var}\left(y_{1} - y_{2}\right) = \text{Var}\left(y_{1}\right) + \text{Var}\left(y_{2}\right) - 2\text{Cov}\left(y_{1},y_{2}\right).
\]</div>
<p>Here, <span class="math notranslate nohighlight">\(\text{Cov}\)</span> stands for <em>covariance</em>, which is simply un-normalised correlation. From this we can see that the degree of correlation is necessary to get this value right. If we are trying to calculate differences between conditions of an experiment that are repeated measurements, we need to know the correlation, otherwise our standard errors will be wrong, our test-statistics will be wrong and the <span class="math notranslate nohighlight">\(p\)</span>-values will be wrong. As such, the accuracy of our inference depends upon using suitable methods that allow this correlation to be accommodated.</p>
</div>
</section>
<section id="the-relationship-is-a-straight-line">
<h3>(4) The Relationship is a Straight Line<a class="headerlink" href="#the-relationship-is-a-straight-line" title="Link to this heading">#</a></h3>
<p>One of the more obvious assumptions we have made within our regression model is that the relationship in the population is a <em>straight line</em>. This is not something we can every truly know, however, we need to examine whether a straight line appears <em>reasonable</em>, given the data we have available. We do not expect that any true relationship will be a perfect straight line. This is a simplifying assumption and so the aim is to see how <em>close</em> a straight line fit is within the data we have available. This is one of the few assumptions where there is no alternative to simply visualising the model fit and seeing whether it appears accurate. As we will see in the next part of this lesson, there are ways of assessing this visually without producing added-variable plots for each predictor, however, these types of plots are needed for understanding the contribution of each variable to any potential poor-fit. It could be that it is only one variable where a straight-line does not appear appropriate, or there could be several variables where this appears untenable. We will see how we can adjust predictors to accommodate any <em>non-linearities</em> in the fit later in this lesson. Using the general modelling framework we established previously, this can be thought of as the assumption that our <em>mean function</em> has the correct form.</p>
</section>
<section id="the-variance-is-constant">
<h3>(5) The Variance is Constant<a class="headerlink" href="#the-variance-is-constant" title="Link to this heading">#</a></h3>
<p>As a final assumption, we turn to the <em>variance</em> of the assumed distribution. Much like the assumption of a straight line concerns the correct form of the <em>mean function</em>, we also need to consider whether the <em>variance function</em> has a suitable form for our data. As mentioned in previous lessons, both simple and multiple regression have a very simply variance functions, where we assume that the spread of data around the regression line is <em>the same</em>, irrespective of the values of the predictors. This is captured by a <em>constant</em> variance term <span class="math notranslate nohighlight">\(\sigma^{2}\)</span>. Like other elements of the model, this is a <em>simplifying assumption</em>. We do not expect any real-world data to actually have <em>identical</em> spread around the regression line. If it is similar-enough across the range of the predictors, then we can continue with the assumption that the population variance is constant. However, if there is any clear pattern, such as variance <em>increasing</em> or <em>decreasing</em> as the values of the predictors change, then this assumption may not be tenable. The condition of having constant variance is known as <em>homoscedasticity</em>, with unequal variance known as <em>heteroscedasticity</em><a class="footnote-reference brackets" href="#scedasis-foot" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>. The problem with <em>heteroscedasticity</em> is that calculating a single variance terms from data where the variance changes will introduce bias in the form of <em>over-estimation</em> for some data points, and <em>under-estimation</em> for other data points. This also has a direct consequence for the accuracy of estimating the other parameters in the model, as well as calculating correct standard errors. So much like assumptions around correlation, we need the variance to be correct in order to guarantee accurate inference.</p>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="prime-foot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>So, <span class="math notranslate nohighlight">\(\text{Corr}\left(y_{i},y_{i^{\prime}}\right)\)</span> just means “the correlation between two different values of <span class="math notranslate nohighlight">\(y\)</span>”.</p>
</aside>
<aside class="footnote brackets" id="repmeasures-foot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>It is an interesting quirk of traditional statistical education in Psychology that repeated measures are introduced so early on. For Experimental Psychologists, repeated measurement designs (also known as <em>within-subject</em> designs) are very common because they allow for increased power and for each subject to act as their own control. However, the early introduction of this topic belies the degree of complexity that is added when it comes to statistical modelling. This can lead students astray, as the assumption is that repeated measurements should be easy to analyse, when this is actually far from the reality.</p>
</aside>
<aside class="footnote brackets" id="scedasis-foot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p>These terms have their roots in the Greek word “skedasis”, which means <em>dispersion</em> or <em>scattering</em>. So, homoscedasticity literally means “equal scattering” and heteroscedasticity literally means “unequal scattering”.</p>
</aside>
</aside>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="0.intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Introduction</p>
      </div>
    </a>
    <a class="right-next"
       href="2.data-features.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Data Features</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-nature-of-assumptions-visual-checks-and-tests">The Nature of Assumptions, Visual Checks and Tests</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-visual-assessments">Using Visual Assessments</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-tests-of-assumptions-are-flawed">Why Tests of Assumptions are Flawed</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-regression-assumptions">The Regression Assumptions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-outcome-is-a-continuous-random-variable">(1) The Outcome is a Continuous Random Variable</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-distribution-of-the-errors-is-normal">(2) The Distribution of the Errors is Normal</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-data-errors-are-uncorrelated">(3) The Data/Errors are Uncorrelated</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-relationship-is-a-straight-line">(4) The Relationship is a Straight Line</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-variance-is-constant">(5) The Variance is Constant</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr George Farmer & Dr Martyn McFarquhar
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2026.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>