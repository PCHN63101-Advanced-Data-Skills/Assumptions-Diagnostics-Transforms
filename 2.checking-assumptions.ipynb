{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6b3fd6-1753-45e7-a920-fccf68cbdcac",
   "metadata": {},
   "source": [
    "# Checking the Assumptions\n",
    "Now that we have established the nature of testing assumptions visually, as well as introducing the core assumptions made by a linear model, we can start investigating *how* to check the assumptions. Before getting there, we first need to discuss some data features that are not assumptions per-se, but which can point to invalid assumptions, or can unduly influence the model fit. We will then look at information we can extract from the model to help us assess whether these data features are present, as well as helping us assess the model assumptions. Finally, we will examine a standard selection of plots that can be used for diagnostic purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dc709f",
   "metadata": {},
   "source": [
    "## Data Features that May Invalidate the Model\n",
    "\n",
    "### Outliers\n",
    "Can distort estimates, inflate variance, and affect inference.\n",
    "\n",
    "### High Leverage Points \n",
    "Data points with unusual predictor values that can overly influence the fit.\n",
    "\n",
    "### Multicollinearity\n",
    "*Perfect* multicollinearity would cause the model estimation to *fail*. So, in `R`, when we have two variables that are perfectly correlated, one will have all its associated estimates set to `NA`, as we can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4291ed43",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = mpg ~ wt + wt.copy, data = mtcars)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-4.5432 -2.3647 -0.1252  1.4096  6.8727 \n",
       "\n",
       "Coefficients: (1 not defined because of singularities)\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  37.2851     1.8776  19.858  < 2e-16 ***\n",
       "wt           -5.3445     0.5591  -9.559 1.29e-10 ***\n",
       "wt.copy           NA         NA      NA       NA    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 3.046 on 30 degrees of freedom\n",
       "Multiple R-squared:  0.7528,\tAdjusted R-squared:  0.7446 \n",
       "F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data(mtcars)\n",
    "wt.copy <- mtcars$wt\n",
    "mod     <- lm(mpg ~ wt + wt.copy, data=mtcars)\n",
    "summary(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da2e666",
   "metadata": {},
   "source": [
    "We can see that a warning had been generated saying that one coefficient is `not defined because of singularities`. This is an obvious problem that has been dealt with gracefully. The more insidious issue is when we have multicollinearity that is *high*, rather than *perfect*. We can generate a predictor with a high correlation (but not perfect correlation) by simply adding some random noise to the copy of the `wt` variable, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d165ba72",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.9734991\n"
     ]
    }
   ],
   "source": [
    "set.seed(666)\n",
    "data(mtcars)\n",
    "wt      <- mtcars$wt\n",
    "wt.copy <- wt + rnorm(n=length(wt), mean=0, sd=0.2)\n",
    "print(cor(wt,wt.copy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf4535c",
   "metadata": {},
   "source": [
    "So, we can see that `wt` and `wt.copy` have a correlation of $r = 0.97$, which would be considered very high. Now let us see what happens when these are both in the same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82e4a3d6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = mpg ~ wt + wt.copy, data = mtcars)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-4.2881 -2.4767 -0.0536  1.6162  6.6278 \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)   37.561      1.938  19.377   <2e-16 ***\n",
       "wt            -6.966      2.467  -2.824   0.0085 ** \n",
       "wt.copy        1.559      2.309   0.675   0.5049    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 3.074 on 29 degrees of freedom\n",
       "Multiple R-squared:  0.7567,\tAdjusted R-squared:  0.7399 \n",
       "F-statistic: 45.09 on 2 and 29 DF,  p-value: 1.259e-09\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod.multicol <- lm(mpg ~ wt + wt.copy, data=mtcars)\n",
    "summary(mod.multicol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f4e46",
   "metadata": {},
   "source": [
    "Notice that the standard error of `wt` has *increased* dramatically from 0.559 to 2.467. This is effectively a *four-fold* increase in uncertainty, with the $t$-statistic close to *one third* of its original value, going from -9.559 to -2.824. This is often referred to as the standard errors *blowing-up*, due to the increased uncertainty that the correlation introduces. We will discuss ways of diagnosing this below and then will discuss some \"solutions\" later in the lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7147d0",
   "metadata": {},
   "source": [
    "## Model Outputs for Checking Assumptions\n",
    "\n",
    "### Residuals\n",
    "\n",
    "### Standardised Residuals\n",
    "\n",
    "### Predicted Values\n",
    "\n",
    "### Leverage Values\n",
    "\n",
    "### The Variance Inflation Factor (VIF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba452871",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       wt   wt.copy        hp \n",
      "21.917371 19.766097  1.826262 \n"
     ]
    }
   ],
   "source": [
    "library(car)\n",
    "print(vif(mod.multicol))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58debbad",
   "metadata": {},
   "source": [
    "In general, we can take:\n",
    "\n",
    "- VIF = 1 - No multicollinearity\n",
    "- 1 < VIF < 5 - Moderate multicollinearity. Some caution may be needed, but not necessarily a problem for the model\n",
    "- VIF > 5 - Very high multicollinearity. Almost certainly an issues and some mitigation will be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e89221",
   "metadata": {},
   "source": [
    "## Standard Diagnostic Plots\n",
    "\n",
    "### Residual vs Fitted Plot\n",
    "\n",
    "### Q-Q Normal Plot\n",
    "\n",
    "### Scale vs Location Plot\n",
    "\n",
    "### Residuals vs Leverage Plot\n",
    "Cook's distance..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2271863",
   "metadata": {},
   "source": [
    "`````{admonition} Residuals are Not Independent with Constant Variance\n",
    ":class: tip\n",
    "One of the main reasons for distinguishing between *errors* and *residuals* is that the estimation process *changes* the distributional properties of the errors. This means that *errors* and *residuals* are not expected to behave idnetically. So while it is correct to assume\n",
    "\n",
    "$$\n",
    "\\epsilon_{i} \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{N}\\left(0,\\sigma^{2}\\right),\n",
    "$$\n",
    "\n",
    "it is *not* technically correct to assume the same for the *errors*. This is because the estimation procedure can *induce* correlation between the errors and the errors can have non-constant variance, depending upon a property known as *leverage*. We will discuss some of these concepts next week. For now, just note that the residuals can be used as an *approximation* for the errors, but we need to perform some additional checks to make sure that this approximation is reasonable.\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf96efc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
